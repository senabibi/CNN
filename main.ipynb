{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f593c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive, userdata\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import time\n",
    "\n",
    "# ==========================================\n",
    "# STEP 0: Initialize wandb with Colab Secrets\n",
    "# ==========================================\n",
    "if wandb.run is not None:\n",
    "    wandb.finish()\n",
    "\n",
    "try:\n",
    "    os.environ[\"WANDB_API_KEY\"] = userdata.get('WANDB_API_KEY')\n",
    "    wandb.login()\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing Secrets: {e}. Please ensure 'WANDB_API_KEY' is enabled in the Secrets tab.\")\n",
    "\n",
    "wandb.init(\n",
    "    project=\"VGG-flowers-v3\",\n",
    "    name=\"vgg16-transfer-learning-run1\",\n",
    "    reinit=True,\n",
    "    config={\n",
    "        \"epochs\": 50,\n",
    "        \"batch_size\": 16,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"architecture\": \"VGG16\",\n",
    "        \"pretrained\": True,\n",
    "        \"input_size\": 224\n",
    "    }\n",
    ")\n",
    "\n",
    "config = wandb.config\n",
    "\n",
    "# =======================\n",
    "# STEP 1: Mount Drive and Access Shared Dataset\n",
    "# =======================\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Your Google Drive shared folder ID\n",
    "SHARED_FOLDER_ID = \"1dKehfyJoRDQpHZ6qJ5VQgNgiLdzMVXeH\"\n",
    "\n",
    "print(\"Attempting to locate dataset...\")\n",
    "\n",
    "# Find the correct data directory\n",
    "data_root = None\n",
    "possible_dirs = [\n",
    "    \"/content/drive/MyDrive/5flowersdata\",\n",
    "    \"/content/drive/MyDrive/flowers\",\n",
    "    \"/content/drive/.shortcut-targets-by-id/\" + SHARED_FOLDER_ID,\n",
    "    \"/content/drive/Shareddrives/5flowersdata\",\n",
    "]\n",
    "\n",
    "# Add specific sub-path checks\n",
    "for dir_path in possible_dirs:\n",
    "    if os.path.exists(dir_path):\n",
    "        # Check root of path\n",
    "        if os.path.exists(os.path.join(dir_path, \"train\")):\n",
    "            data_root = dir_path\n",
    "            break\n",
    "        # Check for nested 'flowers' folder\n",
    "        elif os.path.exists(os.path.join(dir_path, \"flowers\", \"train\")):\n",
    "            data_root = os.path.join(dir_path, \"flowers\")\n",
    "            break\n",
    "\n",
    "if data_root is None:\n",
    "    print(\"\\nFolders found in MyDrive:\", os.listdir('/content/drive/MyDrive'))\n",
    "    raise FileNotFoundError(\"Dataset not found. Please ensure the shared folder is added to your Drive as a shortcut.\")\n",
    "\n",
    "train_dir = os.path.join(data_root, \"train\")\n",
    "val_dir = os.path.join(data_root, \"val\") if os.path.exists(os.path.join(data_root, \"val\")) else os.path.join(data_root, \"validation\")\n",
    "\n",
    "# =======================\n",
    "# STEP 2: Data Preparation\n",
    "# =======================\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((config.input_size, config.input_size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((config.input_size, config.input_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=data_transforms['val'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# ===========================\n",
    "# STEP 3: Model Configuration\n",
    "# ===========================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.vgg16(pretrained=config.pretrained)\n",
    "\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# ===========================\n",
    "# STEP 4: Training Setup\n",
    "# ===========================\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        val_correct, val_total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        scheduler.step(val_acc)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Val Acc: {val_acc:.4f}\")\n",
    "        wandb.log({\"epoch\": epoch+1, \"val_accuracy\": val_acc, \"loss\": running_loss/len(train_loader)})\n",
    "\n",
    "# Start Training\n",
    "train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, config.epochs)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
