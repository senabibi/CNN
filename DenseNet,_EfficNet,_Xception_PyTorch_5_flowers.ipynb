{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ekVzSW8Bb_Ze",
        "outputId": "1ba824da-7584-4cf2-c708-ca4a2de1b6b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HUjjD6MRYJmr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "import wandb\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zxVl69yfYLO3"
      },
      "outputs": [],
      "source": [
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ti4rs4tkYMos"
      },
      "outputs": [],
      "source": [
        "# =======================\n",
        "# STEP 1: Data Preparation\n",
        "# =======================\n",
        "\n",
        "# Transforms for training and validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "train_dir = \"/content/drive/MyDrive/5flowersdata/flowers/train\"\n",
        "val_dir = \"/content/drive/MyDrive/5flowersdata/flowers/val\"\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=data_transforms['train'])\n",
        "val_dataset = datasets.ImageFolder(root=val_dir, transform=data_transforms['val'])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Uu1_CDgvYOEW"
      },
      "outputs": [],
      "source": [
        "# Training Function\n",
        "def train_model(model, model_name):\n",
        "    wandb.init(project=f\"{model_name}-flowers\", config={\n",
        "        \"epochs\": 50,\n",
        "        \"batch_size\": 16,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"architecture\": model_name,\n",
        "        \"pretrained\": True\n",
        "    })\n",
        "    config = wandb.config\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=config.learning_rate)\n",
        "    wandb.watch(model, log=\"all\", log_freq=10)\n",
        "\n",
        "    for epoch in range(config.epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        train_acc = correct / total\n",
        "        wandb.log({\"train_loss\": train_loss, \"train_accuracy\": train_acc})\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_correct += (preds == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "        val_acc = val_correct / val_total\n",
        "        wandb.log({\"val_accuracy\": val_acc})\n",
        "        print(f\"Epoch {epoch+1} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mxiVbXfxYPiW"
      },
      "outputs": [],
      "source": [
        "# Model setup functions\n",
        "def get_efficientnet():\n",
        "    model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
        "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, 5)\n",
        "    for param in model.parameters(): param.requires_grad = False\n",
        "    for param in model.classifier[1].parameters(): param.requires_grad = True\n",
        "    return model\n",
        "\n",
        "def get_densenet():\n",
        "    model = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
        "    model.classifier = nn.Linear(model.classifier.in_features, 5)\n",
        "    for param in model.parameters(): param.requires_grad = False\n",
        "    for param in model.classifier.parameters(): param.requires_grad = True\n",
        "    return model\n",
        "\n",
        "def get_xception():\n",
        "    from timm import create_model\n",
        "    model = create_model('xception', pretrained=True, num_classes=5)\n",
        "    for param in model.parameters(): param.requires_grad = False\n",
        "    for param in model.get_classifier().parameters(): param.requires_grad = True\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "_g-opvZQESck",
        "outputId": "f9cc76d8-8819-4124-a733-6f92e2c671ca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name xception to current legacy_xception.\n",
            "  model = create_fn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvizuara-info\u001b[0m (\u001b[33mpritkudale-vizuara\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250619_064325-i1rpsxnf</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/pritkudale-vizuara/Xception-flowers/runs/i1rpsxnf' target=\"_blank\">misunderstood-jazz-3</a></strong> to <a href='https://wandb.ai/pritkudale-vizuara/Xception-flowers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/pritkudale-vizuara/Xception-flowers' target=\"_blank\">https://wandb.ai/pritkudale-vizuara/Xception-flowers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/pritkudale-vizuara/Xception-flowers/runs/i1rpsxnf' target=\"_blank\">https://wandb.ai/pritkudale-vizuara/Xception-flowers/runs/i1rpsxnf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Acc: 0.7275 | Val Acc: 0.8309\n",
            "Epoch 2 | Train Acc: 0.8216 | Val Acc: 0.8398\n",
            "Epoch 3 | Train Acc: 0.8433 | Val Acc: 0.8388\n",
            "Epoch 4 | Train Acc: 0.8500 | Val Acc: 0.8536\n",
            "Epoch 5 | Train Acc: 0.8678 | Val Acc: 0.8586\n",
            "Epoch 6 | Train Acc: 0.8668 | Val Acc: 0.8714\n",
            "Epoch 7 | Train Acc: 0.8718 | Val Acc: 0.8665\n"
          ]
        }
      ],
      "source": [
        "# Main loop\n",
        "model_dict = {\n",
        "    # \"EfficientNet\": get_efficientnet,\n",
        "    # \"DenseNet\": get_densenet,\n",
        "    \"Xception\": get_xception\n",
        "}\n",
        "\n",
        "for name, get_model in model_dict.items():\n",
        "    model = get_model()\n",
        "    train_model(model, name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}